version: 3

vars:
  YELLOW: \033[33m
  RESET: \033[0;0m
  setup_tmp:
    sh: mkdir -p tmp && echo tmp
  out: tmp/out.csv
  show_cnt: 16
  translation: nwt
  translations: asv kj21 nwt
  TMP_DIR:
    sh: mkdir -p "data/tmp" && echo "data/tmp"
  DATA_DIR: "data"
  entities_csv_file: "{{.DATA_DIR}}/{{.translation}}_entities.csv"
  entities_json_file: "{{.DATA_DIR}}/{{.translation}}_entities.json"
  bible_data_json: "{{.DATA_DIR}}/{{.translation}}_bible.json"
  bible_data_csv: "{{.DATA_DIR}}/{{.translation}}_bible.csv"
  BOOKS: |
    Genesis
    Exodus
    Leviticus
    Numbers
    Deuteronomy
    Joshua
    Judges
    Ruth
    1 Samuel
    2 Samuel
    1 Kings
    2 Kings
    1 Chronicles
    2 Chronicles
    Ezra
    Nehemiah
    Esther
    Job
    Psalms
    Proverbs
    Ecclesiastes
    Song of Solomon
    Isaiah
    Jeremiah
    Lamentations
    Ezekiel
    Daniel
    Hosea
    Joel
    Amos
    Obadiah
    Jonah
    Micah
    Nahum
    Habakkuk
    Zephaniah
    Haggai
    Zechariah
    Malachi
    Matthew
    Mark
    Luke
    John
    Acts
    Romans
    1 Corinthians
    2 Corinthians
    Galatians
    Ephesians
    Philippians
    Colossians
    1 Thessalonians
    2 Thessalonians
    1 Timothy
    2 Timothy
    Titus
    Philemon
    Hebrews
    James
    1 Peter
    2 Peter
    1 John
    2 John
    3 John
    Jude
    Revelation
  CHAPTERS: |
    Genesis:50
    Exodus:40
    Leviticus:27
    Numbers:36
    Deuteronomy:34
    Joshua:24
    Judges:21
    Ruth:4
    1 Samuel:31
    2 Samuel:24
    1 Kings:22
    2 Kings:25
    1 Chronicles:29
    2 Chronicles:36
    Ezra:10
    Nehemiah:13
    Esther:10
    Job:42
    Psalms:150
    Proverbs:31
    Ecclesiastes:12
    Song of Solomon:8
    Isaiah:66
    Jeremiah:52
    Lamentations:5
    Ezekiel:48
    Daniel:12
    Hosea:14
    Joel:3
    Amos:9
    Obadiah:1
    Jonah:4
    Micah:7
    Nahum:3
    Habakkuk:3
    Zephaniah:3
    Haggai:2
    Zechariah:14
    Malachi:4
    Matthew:28
    Mark:16
    Luke:24
    John:21
    Acts:28
    Romans:16
    1 Corinthians:16
    2 Corinthians:13
    Galatians:6
    Ephesians:6
    Philippians:4
    Colossians:4
    1 Thessalonians:5
    2 Thessalonians:3
    1 Timothy:6
    2 Timothy:4
    Titus:3
    Philemon:1
    Hebrews:13
    James:5
    1 Peter:5
    2 Peter:3
    1 John:5
    2 John:1
    3 John:1
    Jude:1
    Revelation:22
  # merged from other taskfile - needs cleanup
  COMMA_PAT: '
    s/\([0-9]\),\([0-9]\)/\1\2/g;
    s/,/ /g
    '
  SPACE_PAT: "s/Â / /g; s/;/ /g; s/[[:space:]][[:space:]]*/ /g; s/ $//g"
  SEMICOLON_PAT: "s/;/ /g"
  PLAIN_BASE_DIR: ../newWorldTranslation/english/2013-release-plain-text
  RAW_BASE_DIR: ../newWorldTranslation/english/2013-release
  FILE_PAT: "{{.PLAIN_BASE_DIR}}/*/*"
  # ! merged from other taskfile - needs cleanup

dotenv:
  - .env

tasks:
  default: task -a

  changed_files:
    vars:
      duration: '{{default "5m" .CLI_ARGS}}'
    cmds:
      - |
        fd -HI . -tf  \
          --changed-within={{.duration}} \
          --exclude .ruff_cache \
          --exclude .git \
          --exclude data.old \
          --exclude .pytest_cache \
          --exclude "*.log" \
          --exclude __pycache__
  test:
    cmds:
      - task changed_files -- 3m
      - task search -- 'word of god'
      - task ref -- genesis 1:1
      - task: convert_2_csv
      - task: extract
      - task ref-all -- genesis 1:1
      - task changed_files -- 3m
      - task: occupation

  test-with-tag:
    cmds:
      - task: test
      - task: tag-entities

  project-structure:
    desc: show project structure
    cmds:
      - |
        printf "# project-structure\n\n"
        {
        tree  . \
          -I bin -I local -I __pycache__ -I tmp -I docs -I data.old \
          -I *.csv -I *.json -I *.log -I *.md \
          -I go.sum -I go.mod
        } | sed 's/^/    /g'

  copy-data:
    desc: link bible.json generated by bible-text repo
    cmds:
      - |
        # NOTE: bible-text repo: github.com:GenesisInc/bible-text.git
        cp ../bible-text/data/tmp/nwt_bible.json data/.
        cp ../bible-text/data/tmp/multi_translation.json data/.

  tag-entities-sample:
    aliases:
      - es
    cmds:
      - |
        uv run main.py \
          tag-entities \
          --input-file "{{.bible_data_json}}" \
          --output-json "{{.entities_json_file}}" \
          --output-csv "{{.entities_csv_file}}" \
          --books john \
          --translation "{{.translation}}"

  diff:
    silent: true
    cmds:
      - |
        diff -qr data.old data > diff.log || true

        while read -r line; do
            # Extract filenames from diff output
            old_file=$(echo "$line" | awk '{print $2}')
            new_file=$(echo "$line" | awk '{print $4}')

            # Print the filenames
            echo "Diff for: $old_file vs $new_file"

            # Extract the first 10 lines from each file and compare
            diff --suppress-common-lines -b -W 200 -y <(head -n 20 "$old_file") <(head -n 20 "$new_file") || true
            echo
        done < <(grep "Files" diff.log)

  copy:
    cmds:
      - |
        rsync -a --delete data/ data.old/

  nlp-tag:
    silent: true
    aliases:
      - tag-entities
    desc: tag entities in a translation into 2 output files        ... task nlp-tag -- nwt
    deps:
      - copy
    cmds:
      - |
        bible_file="{{.DATA_DIR}}/{{.CLI_ARGS| default .translation}}_bible.json"
        out_json="{{.DATA_DIR}}/{{.CLI_ARGS| default .translation}}_entities.json"
        out_csv="{{.DATA_DIR}}/{{.CLI_ARGS| default .translation}}_entities.csv"
        if [[ ! -f "${bible_file}" ]]; then
          echo "file ${bible_file} not found, exiting. Try 'task extract'"
          exit 1
        fi
        uv run main.py \
          tag-entities \
          --input-file "${bible_file}" \
          --output-json "${out_json}" \
          --output-csv "${out_csv}" \
          --translation "{{.CLI_ARGS| default .translation}}"
      - task: verify-nlp-tag
      - task: diff

  verify-nlp-tag:
    cmds:
      - |
        out_json="{{.DATA_DIR}}/{{.CLI_ARGS| default .translation}}_entities.json"
        out_csv="{{.DATA_DIR}}/{{.CLI_ARGS| default .translation}}_entities.csv"
        wc -l "${out_json}" "${out_csv}"

  verify_convert_2_csv:
    cmds:
      - |
        wc -l {{.DATA_DIR}}/nwt_bible.csv \
          {{.DATA_DIR}}/asv_bible.csv \
          {{.DATA_DIR}}/kj21_bible.csv

  convert_2_csv:
    silent: true
    cmds:
      - |
        MSG="you may need to run below dependent jobs: \n\t1. load-bibles \n\t2. extract "
        # convert nwt_bible.json to nwt_bible.csv
        if [[ ! -f {{.DATA_DIR}}/nwt_bible.json ]] ; then
          echo "file not found: {{.DATA_DIR}}/nwt_bible.json"
          echo -e "${MSG}"
          exit 1
        fi
        jq -r '
          .nwt | to_entries[] as $book_entry
          | $book_entry.value | to_entries[] as $chapter_entry
          | $chapter_entry.value | to_entries[] as $verse_entry
          | [$book_entry.key, $chapter_entry.key, $verse_entry.key, $verse_entry.value] | @csv
        ' {{.DATA_DIR}}/nwt_bible.json > {{.DATA_DIR}}/nwt_bible.csv
        echo "generated {{.DATA_DIR}}/nwt_bible.csv"

        # convert asv_bible.json to asv_bible.csv
        if [[ ! -f {{.DATA_DIR}}/asv_bible.json ]]; then
          echo "file not found: {{.DATA_DIR}}/asv_bible.json"
          echo -e "${MSG}"
          exit 1
        fi
        jq -r '
          .asv | to_entries[] as $book_entry
          | $book_entry.value | to_entries[] as $chapter_entry
          | $chapter_entry.value | to_entries[] as $verse_entry
          | [$book_entry.key, $chapter_entry.key, $verse_entry.key, $verse_entry.value] | @csv
        ' {{.DATA_DIR}}/asv_bible.json > {{.DATA_DIR}}/asv_bible.csv
        echo "generated {{.DATA_DIR}}/asv_bible.csv"

        # convert kj21_bible.json to kj21_bible.csv
        if [[ ! -f {{.DATA_DIR}}/kj21_bible.json ]]; then
          echo "file not found: {{.DATA_DIR}}/kj21_bible.json"
          echo -e "${MSG}"
          exit 1
        fi
        jq -r '
          .kj21 | to_entries[] as $book_entry
          | $book_entry.value | to_entries[] as $chapter_entry
          | $chapter_entry.value | to_entries[] as $verse_entry
          | [$book_entry.key, $chapter_entry.key, $verse_entry.key, $verse_entry.value] | @csv
        ' {{.DATA_DIR}}/kj21_bible.json > {{.DATA_DIR}}/kj21_bible.csv
        echo "generated {{.DATA_DIR}}/kj21_bible.csv"
      - task: verify_convert_2_csv

  verify_extract:
    cmds:
      - |
        wc -l {{.DATA_DIR}}/asv_bible.json \
          {{.DATA_DIR}}/kj21_bible.json \
          {{.DATA_DIR}}/nwt_bible.json \
          {{.DATA_DIR}}/ojb_bible.json

  extract:
    desc: extract transactions from multi_translation.json         ... task extract
    cmds:
      - |
        # extract asv
        uv run python3 main.py extract --translation "asv" \
          --input-file {{.DATA_DIR}}/multi_translation.json \
          --output-file {{.DATA_DIR}}/asv_bible.json

        # extract kj21
        uv run python3 main.py extract --translation "kj21" \
          --input-file {{.DATA_DIR}}/multi_translation.json \
          --output-file {{.DATA_DIR}}/kj21_bible.json

        # extract nwt
        uv run python3 main.py extract --translation "nwt" \
          --input-file {{.DATA_DIR}}/multi_translation.json \
          --output-file {{.DATA_DIR}}/nwt_bible.json

        # extract ojb
        uv run python3 main.py extract --translation "ojb" \
          --input-file {{.DATA_DIR}}/multi_translation.json \
          --output-file {{.DATA_DIR}}/ojb_bible.json
      - task: verify-extracted-json

  verify-extracted-json:
    cmds:
      - |
        printf "number of books: "
        jq 'keys | length' {{.DATA_DIR}}/multi_translation.json

        printf "chapters in book, 3 john:  "
        jq '."3 john" | keys | length' {{.DATA_DIR}}/multi_translation.json
        printf "chapters in book, Genesis: "
        jq '.genesis | keys | length' {{.DATA_DIR}}/multi_translation.json

        printf "verses in a chapter, 3 John 1: "
        jq '."3 john"."1" | keys | length' {{.DATA_DIR}}/multi_translation.json

        # printf "verses from chapter, 3 John 1:"
        # jq '."3 john"."1" | keys' {{.DATA_DIR}}/multi_translation.json

        printf "total verses in bible: "
        jq 'to_entries | map(.value | to_entries | map(.value | to_entries | length) | add) | add' {{.DATA_DIR}}/multi_translation.json

        printf "Consistency of a Specific Verse"
        jq '."3 john"."1"."1"' {{.DATA_DIR}}/multi_translation.json

        printf "find null entries:"
        jq 'to_entries | map(select(.value | to_entries | map(select(.value | to_entries | map(select(.value == null or .value == [])) | length > 0)) | length > 0))' {{.DATA_DIR}}/multi_translation.json

  uv-sync:
    cmds:
      - |
        uv sync
        uv run python3 -m spacy download en_core_web_sm

  ref:
    vars:
      ex: task ref -- genesis 1:1-1:4 __OR__ task translation=ojb ref -- genesis 1:1-4
    silent: true
    desc: refs from one or more transalations                      ... {{.ex}}
    cmds:
      - |
        printf "%-5s: " {{.translation}}
        uv run python3 main.py reference \
          --input-file {{.DATA_DIR}}/{{.translation}}_bible.json \
          --translation {{.translation}} \
          --reference "{{.CLI_ARGS}}"

  ref-all:
    vars:
      ex: task ref-multi -- genesis 1:1
    silent: true
    desc: refs from one or more transalations                      ... {{.ex}}
    cmds:
      - |
        BOOK=$(echo "{{.CLI_ARGS}}" | awk '{print tolower($1)}')
        CHAPTER=$(echo "{{.CLI_ARGS}}" | awk '{print $2}' | cut -d':' -f1)
        VERSE=$(echo "{{.CLI_ARGS}}" | awk '{print $2}' | cut -d':' -f2)

        # Use jq to extract the specific reference
        jq -r --arg book "$BOOK" --arg chapter "$CHAPTER" --arg verse "$VERSE" \
          '.[$book][$chapter][$verse]' data/multi_translation.json

  search:
    vars:
      ex: task search -- Jesus __OR__ task translation=ojb search -- 'word of god'
    desc: find top 5 matches for a string/phrase                   ... {{.ex}}
    cmds:
      - |
        uv run python3 main.py search --phrase {{.CLI_ARGS}} \
          --input-file "{{.DATA_DIR}}/{{.translation}}_bible.json" \
          --top-n 5 --csv \
          --translation {{.translation}} \
        | mlr --c2p --barred cat

  compare-translations:
    silent: true
    desc: compare number of verse, chapters & books count against transalations
    cmds:
      - echo > tmp/status-out.csv
      - for: { var: translations }
        cmd: |
          jq '
          {
            translation: "{{.ITEM}}",
            total_books: (.{{.ITEM}} | keys | length),
            total_chapters: (.{{.ITEM}} | to_entries | map(.value | keys | length) | add),
            total_verses: (.{{.ITEM}} | to_entries | map(.value | to_entries | map(.value | keys | length) | add) | add)
          }' {{.DATA_DIR}}/{{.ITEM}}_bible.json >> tmp/status-out.csv
      - mlr --j2p --barred cat tmp/status-out.csv

  summary:
    desc: show summary                                             ... task summary
    cmds:
      - |
        psql -U ${DB_USER} -d ${DB_NAME} -t -A -F"," -c "
            SELECT
                type AS \"Type\",
                COUNT(*) AS \"Total\",
                COUNT(DISTINCT text) AS \"Unique\",
                CASE
                    WHEN type = 'PERSON' THEN 'Names of individuals'
                    WHEN type = 'DATE' THEN 'Explicit or implicit date expressions'
                    WHEN type = 'GPE' THEN 'Geopolitical entities (places)'
                    WHEN type = 'ORG' THEN 'Organizations or groups'
                    WHEN type = 'OCCUPATION' THEN 'Roles or professions'
                    WHEN type = 'LIFESPAN' THEN 'Lifespan of persons'
                    WHEN type = 'NORP' THEN 'Nationalities religious or political groups'
                    ELSE 'Other'
                END AS \"Explanation\"
            FROM bible_entities
            GROUP BY type
            ORDER BY type
        " | mlr --icsv --c2p --implicit-csv-header --barred label item,total,uniq,exp

  legends:
    desc: legend summary                                           ... task legend
    silent: true
    cmds:
      - |
        mlr --c2p --barred --from {{.entities_csv_file}} \
          count-distinct -f Type \
          then put '
            $Explanation =
              $Type == "PERSON"     ? "Names of individuals" :
              $Type == "DATE"       ? "Explicit or implicit date expressions" :
              $Type == "GPE"        ? "Geopolitical entities (places)" :
              $Type == "ORG"        ? "Organizations or groups" :
              $Type == "OCCUPATION" ? "Roles or professions" :
              $Type == "LIFESPAN"   ? "Lifespan of persons" :
              $Type == "NORP"       ? "Nationalities, religious or political groups" :
                                      "Other";
          ' \
          then reorder -f Type,count,Explanation then sort -f Type

  trips:
    desc: view journesy in map                                     ... task travels
    cmds:
      - |
        uv run main.py trips

  science:
    desc: scientific matters                                       ... task science
    cmds:
      - |
        uv run main.py science

  org:
    vars:
      ex: task translation=ojb org
    desc: show Organizations or groups                             ... {{.ex}}
    silent: true
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "ORG"' \
          then cut -x -f Extras \
          > {{.out}}
      - task: out
      - echo "Legend.ORG - Organization or groups"

  lifespan:
    vars:
      ex: task translation=ojb LIFESPAN
    desc: show lifespan of people                             ... {{.ex}}
    silent: true
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "LIFESPAN"' \
          > {{.out}}
      - task: out
      # - echo "Legend.ORG - Organization or groups"

  occupation:
    silent: true
    desc: show roles or professions
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "OCCUPATION"'  \
          then cut -x -f Extras \
          > {{.out}}
      - task: out

  unique-occupation:
    aliases:
      - top-occupations
    silent: true
    desc: show roles or professions
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}}  \
            filter '$Type == "OCCUPATION"' \
            then cut -f Trigger \
            then count-distinct -f Trigger \
            then sort -nf count > {{.out}}
      - task: out

  relationship:
    silent: true
    desc: show relationships
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "RELATIONSHIP"' \
          then cut -x -f Extras \
          then sort -nf count > {{.out}}
      - task: out

  event:
    silent: true
    desc: show relationships
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "EVENT"' \
          then cut -x -f Extras \
          then sort -nf count > {{.out}}
      - task: out

  occupation-summary:
    vars:
      ex: task translation=ojb occupation-summary
    desc: show summary of roles or professions                     ... {{.ex}}
    silent: true
    cmds:
      - |
        # sort by occupation
        echo "top and bottom $(( {{.show_cnt}} / 2)) of sorted by occupation"
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "OCCUPATION"' \
            then cut -f Trigger \
            then count-distinct -f Trigger \
            then label occupation,count \
            then cut -x -f Extras \
            then sort -f occupation > {{.out}}
      - task: out
      - |
        # sort by count
        printf "\n\n\ntop and bottom $(( {{.show_cnt}} / 2)) of sorted by count\n"
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "OCCUPATION"' \
            then cut -f Trigger \
            then count-distinct -f Trigger \
            then label occupation,count \
            then cut -x -f Extras \
            then sort -nf count  > {{.out}}
      - task: out

  gpe:
    desc: show Geopolitical entities (places)
    silent: true
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "GPE"' \
          then cut -x -f Extras \
          > {{.out}}

      - task: out
      - echo Legend.GPE - GeoPoliticalEntity

  norp:
    desc: show Nationalities, religious or political groups
    silent: true
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "NORP"' \
          then cut -x -f Extras \
          > {{.out}}
      - task: out
      - echo Legend.NORP - Nationalities Religions or Political Groups

  names:
    vars:
      ex: task translation=ojb names
    silent: true
    desc: show names/persons                                       ... {{.ex}}
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "PERSON"' \
          then cut -x -f Extras \
          > {{.out}}
      - task: out

  unique-names:
    silent: true
    desc: "show unique names/persons"
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "PERSON"' \
          then count-distinct -f Trigger \
          then sort -f Trigger > {{.out}}
      - task: out

  top-names:
    silent: true
    desc: "show unique names/persons"
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter '$Type == "PERSON"' \
          then count-distinct -f Trigger \
          then sort -nf count then tail > {{.out}}
      - task: out

  date:
    silent: true
    desc: "Fetch and format output for DATE=daniel"
    cmds:
      - |
        mlr --csv --from {{.entities_csv_file}} \
          filter  '$Type == "DATE"' \
          then cut -x -f Extras \
          > {{.out}}
      - task: out

  out:
    silent: true
    cmds:
      - |
        total=$(mlr --from {{.out}} --csv --headerless-csv-output count)
        printf "Summary:\n   Total: ${total} records\n"
        top=$(({{.show_cnt}} / 2 + 1))
        btm=$(({{.show_cnt}} / 2 ))

        if [ "$total" -le {{.show_cnt}} ]; then
          # For fewer than or equal to {{.show_cnt}} records, display all
          echo "   Showing all $total records"
          echo -e "   Translation: {{.YELLOW}}{{.translation}}{{.RESET}}"
          cat "{{.out}}" | mlr --c2p --barred cat -n
        else
          # For more than {{.show_cnt}} records, show first ${btm} and last ${btm}
          echo "   Showing {{.show_cnt}} of $total records"
          echo -e "   Translation: {{.YELLOW}}{{.translation}}{{.RESET}}"
          (head -n${top} "{{.out}}" && tail -n${btm} "{{.out}}") | mlr --c2p --barred cat -n
        fi

  # merged from other taskfile - needs cleanup
  clean_symbols:
    cmds:
      - task: semicolon
      - task: comma
      - task: spaces
      - task: remove-symbols
      - task: square-brackets
      - task: special-cases

  special_cases:
    cmds:
      - |
        # Remove only leading or trailing Unicode hyphens (EN DASH and EM DASH),
        #   but keep internal hyphens intact
        sed -i "" 's/^[\ââ]\+//; s/[\ââ]\+$//' {{.FILE_PAT}}

  verify-special-cases:
    cmds:
      - |
        words=("âHe" "âI" "2" "âLet" "Mountains" "âSihon" "âThe" "âprovided" "âthat" "ââ" "perishedâthe")

        for word in "${words[@]}" ; do
          echo "$word" | sed 's/^[\ââ]\+//; s/[\ââ]\+$//'
        done

  square-brackets_2:
    cmds:
      - |
        # cleanup these words
        #   [Ayin]In [Ayin]They [Beth]In [Beth]Who [Daleth]And [Daleth]They
        #   [Lamed]12 [Lamed]By [Nun]He [Nun]Trustworthy [Waw]And
        sed -i "" 's/\[.*\]//g;' {{.FILE_PAT}}

  square-brackets:
    cmds:
      - |
        # Remove text within square brackets
        sed -i "" 's/\[[^]]*\]//g' {{.FILE_PAT}}

  remove-unicode-symbols:
    cmds:
      - |
        # Remove symbols including additional Unicode symbols
        sed -i "" 's/[()ââ.;:âÊ¹Â·"!?â×××ï¬×× ××¢]//g' {{.FILE_PAT}}

  remove-symbols:
    cmds:
      - |
        # remove other symbols
        sed -i "" 's/[()ââ.;:âÊ¹Â·"!?â]//g;' {{.FILE_PAT}}

  spaces:
    cmds:
      - |
        sed -i "" "{{.SPACE_PAT}}" {{.FILE_PAT}}

  semicolon:
    cmds:
      - |
        sed -i "" "{{.SEMICOLON_PAT}}" {{.FILE_PAT}}

  comma:
    cmds:
      - |
        sed -i "" "{{.COMMA_PAT}}" {{.FILE_PAT}}

  split:
    cmds:
      - |
        mkdir -p tmp
        # Split words and numbers
        cat {{.FILE_PAT}} | tr ' ' '\n' > analysis/words.list

        # Separate numbers and words
        grep '^[0-9]' analysis/words.list > tmp/numeric.list
        grep '^[^0-9]' analysis/words.list > tmp/words_only.list

        # Process numeric list: sort numerically and count occurrences
        cat tmp/numeric.list | sort -n | uniq -c | sort -k2,2n > tmp/numeric-counts.list

        # Process words list: sort by count (desc), then alphabetically
        cat tmp/words_only.list | sort | uniq -c | sort -k1,1nr -k2,2 > tmp/words-counts.list

        # Combine both lists: numbers first, then words
        cat tmp/words-counts.list tmp/numeric-counts.list > analysis/word_counts.list

  fix-verse-separator:
    cmds:
      - |
        for file in newWorldTranslation/english/2013-release/*/*; do
          sed -E -i '' 's/^1 /1Â /' "$file"
        done

  split-2:
    cmds:
      - |
        cat {{.FILE_PAT}}  | tr ' ' '\n' > analysis/words.list
        cat analysis/words.list | sort | uniq -c | sort -n > analysis/word_counts.list

  analyze:
    cmds:
      - |
        cat -n analysis/word_counts.list

  verify:
    cmds:
      - |
        words=("day,16" "saying,May" "10,100" "10,x" "x,10" "them,Because" "multi   spaces" "greedy one; [Nun]He")

        for word in "${words[@]}" ; do
          echo "$word" \
            | sed "{{.COMMA_PAT}}" \
            | sed "{{.SPACE_PAT}}"
        done
  run: task -p gen_tag gen_lifespan
  gen_tag:
    parellel: true
    cmds:
      - uv run main.py lifespan --tag

  person_lifespan:
    desc: persons with lifespan in bible.json
    cmds:
      - |
        jq -r '
        to_entries[] | .value |
        to_entries[] | .value |
        keys[]' analysis/lifespans.json \
        | sort \
        | uniqÃ¥

  gen_lifespan:
    parellel: true
    cmds:
      - uv run main.py --extract-lifespan

  wc:
    cmds:
      - |
        wc {{.FILE_PAT}}

  refresh_plain_text:
    cmds:
      - |
        rm -rf {{.PLAIN_BASE_DIR}}
        cp -r {{.RAW_BASE_DIR}} {{.PLAIN_BASE_DIR}}

  # ! merged from other taskfile - needs cleanup
